---
title: Insert title here
key: 37d7d11af5613069547b123ccc47ed77

---
## Handling Errors and Missing Data

```yaml
type: "TitleSlide"
key: "e8067e90dc"
```

`@lower_third`

name: Amany Mahfouz
title: undefined


`@script`
So far, you’ve worked on importing different flat files, like csvs and tab-separated files, and customizing imports to set field names and get only the data you're interested in. All of this is great if your dataset is clean, with obvious data types, clearly labeled missing values, and no other errors. But what if there are issues with the data or the import?


---
## Common Data Import Issues

```yaml
type: "FullSlide"
key: "4e9d475a9d"
```

`@part1`
* Wrong data types
* Missing values
* Errors in lines


`@script`
Datasets often have missing values, missing values encoded in unexpected ways, or records with errors; sometimes, data is read in as the wrong type, making it harder to analyze. Luckily, the pandas read_csv method offers ways to address these issues right at the import stage, reducing the amount of wrangling you have to do later on.


---
## Specifying Data Types

```yaml
type: "TwoRows"
key: "22caa3e64d"
```

`@part1`



`@part2`
```
import pandas as pd

data = pd.read_csv(file, dtype={‘zip_code’: str})
```


`@script`
When you read a csv with pandas, pandas does its best to sniff out what data type each field should be. However, it doesn’t always get it right. For example, here is a csv with a zip_code field for US postal codes. Even though the values are all numbers, we want to treat them as strings (or, in the language of pandas, as objects)
Instead of letting pandas guess, we can tell it exactly what data type any or all of the fields in a csv should be, using the ```dtype``` parameter in ```read_csv```
```dtype``` takes a dictionary, where each key is a field and each value is the data type that field should be. Here, we ensure ZIP codes are strings with the following code:


---
## Setting Custom Missing Data Values

```yaml
type: "TwoRows"
key: "8e8f83d823"
```

`@part1`



`@part2`
```
import pandas as pd

data = pd.read_csv(file, na_values=[])
```


`@script`
Pandas automatically looks out for certain values, like “N/A” or “null”  when importing data and re-codes them as missing values.  But sometimes, missing values in your data might be represented differently, such as with dashes (“--”) or “none”.
You can tell pandas to treat these entries as missing values with the ```na_values``` parameter in ```read_csv```
```na_values``` can take a list of values that should be coded as N/As or NaNs. It can even take a dictionary, where each key-value pair represents a field and a list of the values in that field to treat as N/As.


---
## Skipping Blank Lines and Lines with Errors

```yaml
type: "TwoRows"
key: "e03fcbdf7b"
```

`@part1`



`@part2`



`@script`



---
## Final Slide

```yaml
type: "FinalSlide"
key: "bc2d10733a"
```

`@script`



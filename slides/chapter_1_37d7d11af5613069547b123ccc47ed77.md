---
title: Insert title here
key: 37d7d11af5613069547b123ccc47ed77

---
## Handling Errors and Missing Data

```yaml
type: "TitleSlide"
key: "e8067e90dc"
```

`@lower_third`

name: Amany Mahfouz
title: Instructor


`@script`
So far, you’ve worked on importing different flat files, like csvs and tsvs, and customizing imports to set better field names and get only the data you're interested in. That might be enough if your data is in great shape to begin with. But what if there are issues with the data or the import?


---
## Common Flat File Import Issues

```yaml
type: "FullSlide"
key: "4e9d475a9d"
disable_transition: false
```

`@part1`
* Column data types are wrong {{1}}
* Values are missing {{2}}
* Lines contain errors, like too many fields {{3}}


`@script`
Files can be imported with incorrect data types, making your data harder to analyze. Datasets can also have missing values, custom missing value designators, or records that have errors. Luckily, the pandas read_csv method offers ways to address these issues at the import stage, reducing the wrangling you have to do later on.


---
## Specifying Data Types

```yaml
type: "TwoRows"
key: "22caa3e64d"
```

`@part1`
![](https://lh6.googleusercontent.com/Jx-Tu0YVqi4Mfo5X3DSMCTm0L76o7pr3dcpagj71-8h7jck8w-XamQX0xx7EYMWqqV0EDIcBVLfOkQ=w1920-h903) {{1}}


`@part2`
```
import pandas as pd

data = pd.read_csv(file, dtype={‘zipcode’: str})
```{{2}}


`@script`
When you import flat files, pandas infers each column's data type. However, it doesn’t always get it right. For example, here is a csv of 2016 tax return data by ZIP code for the state of Vermont. By default, pandas will interpret zipcode as an integer field, but it's more accurately modeled as strings.
Instead of letting pandas guess, we can tell it exactly what data type any or all of the fields should be using the dtype parameter in read_csv. dtype takes a dictionary, where each key is a field and each value is the data type that field should be. Here, we'll specify that zipcode should be a string field and let pandas infer the other columns.


---
## Setting Custom Missing Data Values

```yaml
type: "FullSlide"
key: "c4ac8549d0"
```

`@part1`
![](https://lh6.googleusercontent.com/CC8of9zaUZp1bAdckaWfo_yl5zmWRX76OdXwCjKXqoo0BQ2TwA34fhYuE6tyOvAgLB69qz8Ddj36aQ=w1920-h903) {{1}}

```
import pandas as pd
file = 'vermont_tax_data_2016.csv'
data = pd.read_csv(file, dtype={'zipcode': str}, na_values={'zipcode':'0'})
```{{2}}

![](https://lh4.googleusercontent.com/-0z1FoWp1ge0N3fvvhpWfLzibw_Lblp8YJM6OV2hV08zRdQ0I7pC6BWBK16GX2ejJe123sCeFBEH9w=w1920-h903){{3}}


`@script`
Often, datasets will have missing values. Pandas automatically looks out for certain values, like “N/A” or “null”,  when importing data and interprets them as missing, which allows you to make use of some handy data-cleaning functions later on. But sometimes missing values are represented in ways that pandas won't catch, such as with the text “none” or a dummy code. Back in our Vermont tax data, some records had a ZIP code value of 0, which is not a valid postal code and should be treated as missing.

You can tell pandas to treat these entries as missing data with the read_csv's na_values parameter. This can be a single value or a list. You can even set column-specific N/A values by providing a dictionary of columns and values in that column to treat as missing. Here, we'll specify that any zeroes in the zipcode column should be coded as missing data.


---
## Lines with Errors

```yaml
type: "TwoRows"
key: "e03fcbdf7b"
```

`@part1`
![](https://lh5.googleusercontent.com/dbx6ZHFREHw7HtVvKtDkDfQhpVE5h5j0GWQIoK4_v3u7H1JYyCCpmEW6s0-7Evvv6lO_Of78sunbSg=w1920-h903) {{1}}


`@part2`
```
import pandas as pd
data = pd.read_csv(file, error_bad_lines=False, warn_bad_lines=True)
``` {{2}}


`@script`
One last issue you may face are lines that pandas just can't parse. For example, a record could have more values than there are columns, like the second record in this corrupted version of the Vermont tax data.

In this case, you will get an error that pandas could not parse the file, and no data will be imported. Luckily, there is an option to skip unparseable lines and read in the rest of the data. Setting the error_bad_lines parameter to False will cause pandas to skip bad records but continue the import. It's a good idea to also set the warn_bad_lines parameter to True so you can see if any lines were skipped.

A word of caution: if you find that lines were skipped due to errors, it's worth investigating what was left out and why, to see if there are underlying issues that should be addressed in your analysis.


---
## Practice!

```yaml
type: "FinalSlide"
key: "bc2d10733a"
```

`@script`
In this video, you've learned about some common issues analysts face when importing data from flat files, and how to handle those issues. Now, it's your turn to practice. Good luck!


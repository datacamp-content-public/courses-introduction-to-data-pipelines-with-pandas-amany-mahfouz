---
title: Insert title here
key: 37d7d11af5613069547b123ccc47ed77

---
## Handling Errors and Missing Data

```yaml
type: "TitleSlide"
key: "e8067e90dc"
```

`@lower_third`

name: Amany Mahfouz
title: undefined


`@script`
So far, you’ve worked on importing different flat files, like csvs and tsvs, and customizing imports to set better field names and get only the data you're interested in. That might be enough if your data is in great shape to begin with. But what if there are issues with the data or the import?


---
## Common Flat File Import Issues

```yaml
type: "FullSlide"
key: "4e9d475a9d"
```

`@part1`
* Column data types are wrong
* Values are missing
* Lines contain errors, like too many fields


`@script`
Datasets often have missing values, custom missing value designators, or records that have errors; sometimes, data is read in as the wrong type, making it harder to analyze. Luckily, the pandas read_csv method offers ways to address these issues at the import stage, reducing the wrangling you have to do later on.


---
## Specifying Data Types

```yaml
type: "TwoRows"
key: "22caa3e64d"
```

`@part1`
* Pandas will try to guess column data types, but it doesn't always get it right
* Use the `dtype` parameter in `read_csv` to specify any or all column data types
* `dtype` takes a dictionary as an argument


`@part2`
```
import pandas as pd

data = pd.read_csv(file, dtype={‘zipcode’: str})
```


`@script`
When you read flat file with pandas, pandas infers each column's data type. However, it doesn’t always get it right. For example, here is a csv of 2016 tax return data by ZIP code for the state of Vermont. Pandas interprets zipcode as an integer field, but it should be strings.
Instead of letting pandas guess, we can tell it exactly what data type any or all of the fields should be using the ```dtype``` parameter in ```read_csv```.
```dtype``` takes a dictionary, where each key-value pair is a field and the data type that field should be. Here, we ensure ZIP codes are strings with the following code:


---
## Setting Custom Missing Data Values

```yaml
type: "TwoRows"
key: "8e8f83d823"
```

`@part1`



`@part2`
```
import pandas as pd
file = 'vermont_tax_data_2016.csv'
data = pd.read_csv(file, na_values=['0', '99999'])
```


`@script`
Pandas automatically looks out for certain values, like “N/A” or “null”,  when importing data and re-codes them as missing values, allowing you to make use of some handy data-cleaning functions later on. But sometimes, missing values in your data might be represented differently, such as with a dummy code or the text “none”.
You can tell pandas to treat these entries as missing values with the ```na_values``` parameter in ```read_csv```.
```na_values``` can take a list of values that should be coded as N/As. You can even set column-specific N/A values by passing in a dictionary, where each key-value pair represents a field and a list of values in that field to treat as N/As. Back in our Vermont tax data, we can have the dummy zip codes 0 and 99999 imported as N/A values instead.


---
## Blank Lines and Lines with Errors

```yaml
type: "TwoRows"
key: "e03fcbdf7b"
```

`@part1`



`@part2`
```
import pandas as pd
data = pd.read_csv(file, error_bad_lines=False, warn_bad_lines=True)
```


`@script`
One last issue you may face are entirely bad lines of data. For example, a record could have too many fields, in which case, pandas won't import the file at all. You can tell pandas to skip these lines using a few parameters in read_csv. Setting error_bad_lines to False will cause pandas to skip bad records but continue the import. You won't know about skipped lines unless you set warn_bad_lines to True as well, though.

A word of caution: if you find that lines are being skipped due to errors, it's a good idea to investigate what's being left out and why, to see if there are underlying issues that can be addressed or should be accounted for in your analysis.


---
## Final Slide

```yaml
type: "FinalSlide"
key: "bc2d10733a"
```

`@script`
In this video, you've learned about some common issues analysts face when importing data from flat files, and how to handle those issues. Now, it's your turn to practice. Good luck!

